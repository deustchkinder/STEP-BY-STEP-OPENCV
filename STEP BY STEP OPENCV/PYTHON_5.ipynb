{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39c9dd7b-e56e-4828-aa1c-88fbd2927b3a",
   "metadata": {},
   "source": [
    "**VİDEOLAR ÜZERİNDE ÇALIŞMA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09322df-1b94-46ea-ab5c-1b93a2be7cb6",
   "metadata": {},
   "source": [
    "**1-)VİDEO NEDİR?**\n",
    "\n",
    "Video;film,dizi,hareketli resim,anlık akış kaydetme veya bunların bir ekranda gösterilmesi anlamlarına gelmektedir. **FLİPBOOK**\n",
    "\n",
    "Videoların oluşumu benzer şekilde resimlerin arka arkaya gösterilmesi denilebilir.Burada akla ilk gelecek soru ne kadar sürede ve ne kadar resmin arka arkaya geleceğidir. **FRAME**\n",
    "\n",
    "Bir saniye içerisinde gösterilebilecek resim miktarı(Saniye Başına Kare)(Frame Per Second)(FPS) veya FRAME RATE'tir. Performans-Gerçeklik-Harekt/Detay kriterleri vardır.\n",
    "1. Gerçeklik:Gözleri yormayan bir akıcılık elde etme\n",
    "2. Hareket:Saniye başına kayıt edilecek kare sayısı ne kadar fazla ise o kadar detayın kaydedilmesi ve yakalanması mümkün olacaktır.\n",
    "3. Performans:FPS değerlerinin oluşturmak veya görüntülemek için yüksek seviyeli donanım ihtiyacı.\n",
    "\n",
    "!Yüksek FPS değerleri ile çalışmada donanımın desteklemesi gerekliliği unutulmamalıdır.\n",
    "\n",
    "**Video dosyaları hem resim karelerini hem de ses dosyasını birlikte senkronize edilmiş biçimde içeren bir bütündür. Bu içeriğin nasıl görüntüleneceği ve depolanacağı ayarları Kodekler ile yapılır.**\n",
    "\n",
    "OpenCV'de video kayıt etmede FourCC kodeğini kullanabiliriz; DIVX - XVID - H264 - DX50\n",
    "\n",
    "\n",
    "OpenCV'de bilgisayara bağlı olan bir kameraya ulaşmak veya hazır olan bir video dosyasını açmak aynı işlevdir. **VideoCapture()** sınıfının bir nesnesi oluşturulur.Ardından video dosyasından aldığı videoyu frame frame elde etmek için **read()** metodu oluşturulur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ec95a2-b2a6-4e51-8b14-3546d40977f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "video = cv2.VideoCapture(index,apiPreference)\n",
    "video1 = cv2.VideoCapture(filename,apiPreference)\n",
    "read([,image]) #retval(nesnede çözümlenecek frame olup olmadğına),image(nesneden elde edilmiş frame)\n",
    "# index:bilgisayara bağlı kameranın indeks numarası 0 olursa varsayılan kamera(Varsayılan:None) - filename:video dosyasının adres yolu(Varsayılan:None)\n",
    "# apiPreference:Kullanıcının erişemediği alana ulaşmak için kullanılır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34f8f114-d0f3-4037-b6af-54f6c5bb9b87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "if camera.isOpened() == False:\n",
    "    print(\"Doğru gitmeyen bir şeyler var.\")\n",
    "    \n",
    "while camera.isOpened:\n",
    "    ret,frame = camera.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        cv2.imshow(\"Video Dosya Okuma\",frame)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0XFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78dd8dc-21eb-422a-bd63-e4f608494e3f",
   "metadata": {},
   "source": [
    "Video kayıt etmek için **VideoWriter()** Herhangi bir parametre sağlanmadan video dosyasının oluşturulması mümkün değildir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dfed93-b6f8-476d-a366-0f5d751f247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "camera_save = cv2.VideoWriter()\n",
    "cameraSave = cv2.VideoWriter(filename,fourcc,fps,frameSize[,isColor])\n",
    "Camerasave = cv2.VideoWriter(filename,apiPreference,fourcc,fps,frameSize[,isColor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b27230e-6a69-4d8e-bf21-b9dd67021ca2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640\n",
      "360\n",
      "25.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "\n",
    "video = cv2.VideoCapture(\"OneDrive/Belgeler/OpenCV/Kitap/DATA/videoplayback.mp4\")\n",
    "\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "if video.isOpened() == False:\n",
    "    print(\"Doğru gitmeyen bir şeyler var.\")\n",
    "    \n",
    "vw = cv2.VideoWriter('videoplay_gray.mp4',cv2.VideoWriter_fourcc(*'XVID'),fps,(width,height),isColor=False)\n",
    "\n",
    "while video.isOpened:\n",
    "    ret,frame = video.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        time.sleep(1 / fps)\n",
    "        frame = cv2.circle(frame,(55,55),45,color=(255,0,0),thickness=-1)\n",
    "        frame_gray = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        cv2.imshow('Video Dosya Okuma',frame_gray)\n",
    "        vw.write(frame_gray)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0XFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "vw.release()\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(width)\n",
    "print(height)\n",
    "print(fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74398436-b144-4d7b-a681-4f733b3ac544",
   "metadata": {},
   "source": [
    "**!Gerekli durumlarda VideoCapture() sınıfı ile birlikte bir resim sıralaması giriş parametresi olarak sağlanabilir. Bunun için tek gerekli olan parametre olarak düzgün isimlendirme yapılmalıdır. Örneğin img%02.jpg şeklinde girilecek bir parametre img00.jpg,img01.jpg,img02.jpg... şeklinde oluşturulan bir nesneden get() metodu ile alınacak FPS bilgisinin 0 çıkacağı unutulmamalıdır.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5d0cd2-daf0-4997-92a9-02999de1764e",
   "metadata": {},
   "source": [
    "**2-)OPTİCAL FLOW(Optik Akış)**\n",
    "\n",
    "Nesnenin veya kameranın hareketinden kaynaklı iki ardışık çerçeve(frame) arasındaki görünür hareket modelidir.Yani görüntüde nesnelerin nasıl hareket ettiğinin tespit edilmesi işlemidir.Bunun için ardışık iki zaman çerçevesi arasındaki piksel konumunun değişimi hesaplanır.\n",
    "\n",
    "(x,y)&(dx,dy)  -----> (x+dx,y+dx)\n",
    " frame_001(t)          frame_002(t + dt)\n",
    " \n",
    "Optik Akışın Varsayımları:\n",
    "\n",
    "1. Bir nesnenin renk yoğunluğu ve piksel yoğunlukları ardışık kareler arasında önemli ölçüde değişmez.\n",
    "2. Görüntü düzlemindeki birbirine yakın noktalar benzer şekilde hareket eder.\n",
    "(Gerçek hayatta nerede ise imkansızdır.)\n",
    "\n",
    "Görüntü dengeleme ve görüntü sabitlemede kullanılır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6651a7b-333f-45a3-9f0f-db569aac8bc4",
   "metadata": {},
   "source": [
    "**Lucas-Kanade Method**\n",
    "\n",
    "Bu yöntemde belirlenen bir nokta etrafında 3X3'lük piksel kesit alınarak takibi gerçekleştirir.Büyük boyutta olan hareketlerin algılanmasını resim büyüklüğünü küçülterek hareketi de küçültmeye teşvik etmiştir.Amaç görüntüdeki bütün büyük hareketlerin yakalanması mümkün olabilir.\n",
    "\n",
    "OpenCV'de **calcOpticalFlowPyrLK()** fonksiyonu kullanılmaktadır. Öncelikle köşe tespit algoritması kullanılır ardından hareket modeli çıkarılabilir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43474c49-e45d-4d6a-89b1-408b695314cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "status = cv2.calcOpticalFlowPyrLK(prevImg,nextImg,prevPts,nextPts[,status[,err[,winSize[,maxLevel[,criteria[,flags[,minEigThreshold]]]]]]])\n",
    "# prevImg:ilk piramit yapısı - nextImg:ikinci piramit yapısı - prevPts:ilk görüntüde akışın hesaplanacağı koordinat - winSize:taramadan kullanılcak parçacık boyutu(Varsayılan:21,21)\n",
    "# maxLevel:piramit seviye sınırı - criteria:sonlanma kriterleri(TermCRİTERİA) - flags:çalışma biçimi((0),4,8,256)\n",
    "\n",
    "criteria = cv2.TERM_CRITERIA_COUNT + cv2.TERM_CRITERIA_EPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9361d5-c232-4a24-8d07-42d1cacf96f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cornerDetectionCriteria = dict(maxCorners=10,qualityLevel=0.3,minDistance=7,blockSize=7)\n",
    "lucasCriteria = dict(winSize=(200,200),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_COUNT,10,0.03))\n",
    "\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "ret, prevFrame = camera.read()\n",
    "grayPrevFrame = cv2.cvtColor(prevFrame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "prevPoints = cv2.goodFeaturesToTrack(grayPrevFrame,mask=None,**cornerDetectionCriteria)\n",
    "mask = np.zeros_like(prevFrame)\n",
    "\n",
    "if camera.isOpened() == False:\n",
    "    print(\"Doğru gitmeyen bir şeyler var.\")\n",
    "    \n",
    "while camera.isOpened:\n",
    "    ret,currentFrame = camera.read()\n",
    "    grayCurrentFrame = cv2.cvtColor(currentFrame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    nextPoints,status,errors = cv2.calcOpticalFlowPyrLK(grayPrevFrame,grayCurrentFrame,prevPoints,None,**lucasCriteria)\n",
    "    \n",
    "    newmotion = nextPoints[status == 1].reshape(-1,2)\n",
    "    oldmotion = prevPoints[status == 1].reshape(-1,2)\n",
    "    \n",
    "    for i,(new,prev) in enumerate(zip(newmotion,oldmotion)):\n",
    "        x_newPos,y_newPos = new\n",
    "        x_prevPos,y_prevPos = prev\n",
    "        \n",
    "        pt1 = (int(x_newPos), int(y_newPos))\n",
    "        pt2 = (int(x_prevPos), int(y_prevPos))\n",
    "        \n",
    "        mask = cv2.line(mask,pt1,pt2,(0,255,0),2)\n",
    "        currentFrame = cv2.circle(currentFrame,pt1,8,(0,0,255),-1)\n",
    "        \n",
    "        img = cv2.add(currentFrame,mask)\n",
    "        cv2.imshow('takip',img)\n",
    "        \n",
    "        k = cv2.waitKey(10) & 0XFF\n",
    "        if k == 27:\n",
    "            break\n",
    "            \n",
    "        grayPrevFrame = grayCurrentFrame.copy()\n",
    "        nextPoints = newmotion.reshape(-1,1,2)\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f487d32-2d4b-413c-9e13-a3512a9b0dd1",
   "metadata": {},
   "source": [
    "**Derin Oprik Akış Gunner-FarnerBack Algoritması**\n",
    "\n",
    "İlk adım **POLİNOM AÇILIMI**'dır.Her bir pikselin ikinci dereceden polinomları hesaplanarak yakınlaştırılmaktadır.\n",
    "\n",
    "İkinci adım **YER DEĞİŞİMİ TAHMİNİ**'dir.polinominal olarak tahmin edilen her bir komşunun,ötelenmesi kaydırılması sonucu analiz edilir.\n",
    "\n",
    "Üçüncü adım **KARŞILAŞTIRMA**'dır.\n",
    "\n",
    "Renk uzayını **HSV**'den feyiz alır.\n",
    "\n",
    "OpenCV'de **calcOpticalFarneback()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bddc2f-f881-44cd-8024-330b1d693a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "flow = cv2.calcOpticalFlowFarneback(prev,next,flow,pyr_scale,levels,winsize,iterations,poly_n,poly_sigma,flags)\n",
    "# flow:CV_32FC2 tipinde ilk çerçeve ile aynı boyutta hesaplanmış çıkış akış görünütüsü\n",
    "# poly_n:her piksel için polinimal genişlemeyi hesaplamak için kullanılan komşu piksel sayısıdır.\n",
    "# poly_sigma:polinom açılımında kullanılacak türevleri yumuşatmak için gerekli olan gaussian standart sapması değeridir.\n",
    "# poly_n=5,poly_sigma=1.1 -- poly_n=7,poly_sigma=1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245603bf-a32f-45b4-b906-e80b863a418f",
   "metadata": {},
   "source": [
    "**calcOpticalFlowFarneback()** çalıştırıldıktan sonra geriye optik akış hesaplamasının yapılmış olduğu iki boyutlu bir vektör döndürmektedir.Ancak bu fonksiyon ile elde edilen sonuçların görselleştirilmesi yani akış tespiti yapılan piksellerin gösterilebilmesi için elde edilen bu iki boyutlu listede vektör büyüklüklerinin ve açılarının hesaplanması gerekmektedir.\n",
    "\n",
    "OpenCV'de **cartToPolar()** fonksiyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3055a5-a680-47df-9494-bb275b3469fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "magnitude,angle = cv2.cartToPolar(x,y[,magnitude[,angle[,angleInDegrees]]])\n",
    "\n",
    "# x,y:x ve y ekseni bilgileri sağlanır - \n",
    "# magnitude:x parametresiyle aynı boyutta hesaplanılmış çıktının kare farkının kök içerisinde alınmasıdır.\n",
    "# angle:x parametresiyle aynı boyutta hesaplanılmış çıktının radyan ya da derece cinsinden açı bilgisinin alınmasıdır. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3204a9-2c35-49cf-9c38-be5f4446e06e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "ret,prevFrame = video.read()\n",
    "grayPrevFrame = cv2.cvtColor(prevFrame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "hsvMask = np.zeros_like(prevFrame)\n",
    "hsvMask[:,:,1] = 255\n",
    "\n",
    "while True:\n",
    "    ret,nextFrame = video.read()\n",
    "    grayNextFrame = cv2.cvtColor(nextFrame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    flow = cv2.calcOpticalFlowFarneback(grayPrevFrame,grayNextFrame,None,0.5,3,15,3,5,1.1,0)\n",
    "    \n",
    "    magnitude,angle = cv2.cartToPolar(flow[:,:,0],flow[:,:,1],angleInDegrees=True)\n",
    "    hsvMask[:,:,0] = angle / 2\n",
    "    \n",
    "    hsvMask[:,:,2] = cv2.normalize(magnitude,None,0,255,cv2.NORM_MINMAX)\n",
    "    \n",
    "    bgrMask = cv2.cvtColor(hsvMask,cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    cv2.imshow('Dense OF',bgrMask)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0XFF == 27:\n",
    "        break\n",
    "        \n",
    "    prevFrame = nextFrame\n",
    "    \n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9933fb-1aef-4bff-9509-5d8cfcc25b57",
   "metadata": {},
   "source": [
    "**3-)NESNE TAKİP ALGORİTMALARI**\n",
    "\n",
    "Nesne tespiti yapıldıktan sonra aynı şekilde ardışık frame'de kendisini tekraren takibini yapmak önem arz etmektedir.Ayrıca bu işlem o kadar hızlı olmalı ki bu işlem kendini süregelen bir şekilde tekrar edilsin.Hem fiziksel hem de soyutsal değişkenlerin baş göstermesi ile Nesne Takibi bilgisayarlı görü alanın en zor iş parçacık kısmıdır.Nesne Takip Algoritmaları Adımları:\n",
    "\n",
    "1. Takibi yapılacak nesnenin belirlenmesi\n",
    "2. Takip edilecek nesne için özellik çıkarma yöntemleri veya örüntü tanıma ile nesneye özel benzersiz bir kimlik oluşturulması.\n",
    "3. Video'da her ardışık çerçevede tanımlanan kimliğin tekrar edilmesi.\n",
    "\n",
    "OpenCV'de **BOOSTING,MIL,KCF,CSRT,TLD,MedianFlow,MOSSE VE GOTURN** optimize edilen hareket izleminin nesne takip algoritmaları bulunmaktadır.Algoritmaları seçer iken bu hususlar dikkate almalıyız;\n",
    "\n",
    "1. Üzerinde çalışılacak görüntünün hazır bir video dosyasından alınıp/alınmadığı, canlı video akışı olup/olmadığı veya sabit görüntülerden oluşup/oluşmadığı\n",
    "2. Kullanım alanı ve amacı\n",
    "3. Beklenen arka plan gürültüleri ve seviyeleri\n",
    "4. Algılandıktan sonra takibi yapılacak nesnenin farklı boyutlarının bulunması\n",
    "5. Aydınlığın değişme oranı\n",
    "6. Birbiriyle ters orantılı olan hız ve doğruluğun önem dereceleri\n",
    "\n",
    "**Nesne tespit bir görüntüde bulunan nesnenin tanımlanması işlemidir, nesne takip ise herhangi bir nesnenin bir frameden/çerçeveden diğerine değişimini izlemek ve işaretlemektir.Genellikle takip algoritmaları ,tespit algoritmalarından daha hızlıdır.**\n",
    "\n",
    "Aslında görüntü işlemede piksel yoğunluklarına göre kümeleme işlemi yapılacaktır.\n",
    "\n",
    "**Nesne takip uygulamalarında dikkat edilmesi gereken en önemli husus;Takip edilen nesnenin objektifinden ayrılması veya önüne başka engel geçmesiyle birden ortadan kaybolmasıdır.Bu sebeple iyi geliştirilen bir uygulamada bu tür durumlar düşünülmeli,planlanmalı ve başarılı bir şekilde ele alınmalıdır.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef91f5e-237f-40c2-9e74-ee9464fb0baf",
   "metadata": {},
   "source": [
    "**meanShift & camShift Algoritması**\n",
    "\n",
    "meanShift:Kendisine verilen bir pencere içerisindeki piksel yoğunluklarına bakarak yoğunluğu en fazla olduğu alana doğru kendi penceresini kaydırmasıdır.Görüntü üzerinde belirlenen bir alanın histogram eğrisi ve piksel yoğunluğu çıkartılarak, sonradaki çerçevede taramak için kullanılır.\n",
    "\n",
    "Benzersiz bir model oluşturulması için **calcBackProject()** kullanmak bir görüntüdeki piksellerin bir histogramdaki piksel dağılımına göre ne kadar uyumlu olduğunu belirleme ve kayıt etme.Bu fonksiyon ile elde edilen projeye **backProjection** isimlendirilmesi yapılmaktadır bir nevi geri yayılım.Bu hesaplamada 180 derece baz alınır,diğer 180 derece yansıma bazıdır.Histogram eğrisini baz almak için önce HSV renk uzayına ardından normalize etmek gereklidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b84f51e-b40b-4754-b0eb-bea3f4cf5f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "retval,window = cv2.meanShift(probImage,window,criteria)\n",
    "retval1,window1 = cv2.CamShift(probImage,window,criteria)\n",
    "target = cv2.calcBackProject(images,channels,hist,ranges,scale[,dst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41520b18-2e73-4f58-82ef-a5c66d10374b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "ret,prevFrame = video.read()\n",
    "\n",
    "faceDetection = cv2.CascadeClassifier('OneDrive/Belgeler/OpenCV/Kitap/DATA/haarcascades/haarcascade_frontalface_default.xml')\n",
    "faceLocation = faceDetection.detectMultiScale(prevFrame)\n",
    "\n",
    "if len(faceLocation)>0:\n",
    "    (faceX,faceY,w,h) = tuple(faceLocation[0])\n",
    "    faceTracking =(faceX,faceY,w,h)\n",
    "\n",
    "    roi = prevFrame[faceY:faceY + h,  faceX:faceX + w]\n",
    "    hsv_roi = cv2.cvtColor(roi,cv2.COLOR_BGR2HSV) \n",
    "\n",
    "    hist_roi = cv2.calcHist([hsv_roi],[0],None,[180],[0,180])\n",
    "    cv2.normalize(hist_roi,hist_roi,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "    parameters = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT , 10 , 1)\n",
    "\n",
    "    while True:\n",
    "        ret,nextFrame = video.read()\n",
    "        hsv_NextFrame = cv2.cvtColor(nextFrame,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        target = cv2.calcBackProject([hsv_NextFrame],[0],hist_roi,[0,180],1)\n",
    "        ret,faceTracking = cv2.meanShift(target,faceTracking,parameters)\n",
    "\n",
    "        faceX,faceY,w,h = faceTracking\n",
    "\n",
    "        mark = cv2.rectangle(nextFrame,(faceX,faceY),(faceX + w ,faceY + h ),(0,255,255),5)\n",
    "        cv2.imshow('Takip',mark)\n",
    "\n",
    "        k = cv2.waitKey(10) & 0XFF\n",
    "\n",
    "        if k == ord('q'):\n",
    "            break           \n",
    "else:\n",
    "    print(\"DONT FACE DETECTION!\")\n",
    "        \n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fac644-88ff-4b3e-ae1b-257a4049ea71",
   "metadata": {},
   "source": [
    "Kameraya doğru yaklaşan bir aracın görüntüsünde aracın boyutu ve açısı sürekli olarak değişmesine rağmen meanShift ile yapılan nesne takibinde nesne takip penceresi bu değişime göre uyarlanamayacak ve sabit boyutu kalacaktır.Buna çözüm ise **CamShift()** algoritmasıdır.(Continuously Adaptive MeanShift).\n",
    "\n",
    "Öncelikle meanShift algoritması kullanılarak nesne kaymasının veya takibin olduğu konumu hesaplatmaktadır sonrasında algoritmasının her iterasyonunda hesaplanan aynı konum için en ideal elips ölçüsü ve açısının hesaplamasını gerçekleştirir.Bu sayede ardışık framelerde/çerçevelerde yakalanan her hareketi gösteren takip penceresinin açısı ve boyutu güncellenmiş olacaktır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0401954a-dbbd-4355-a82b-0e153a26ecdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emred\\AppData\\Local\\Temp\\ipykernel_7788\\2078378758.py:29: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  points = np.int0(points)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "ret,prevFrame = video.read()\n",
    "\n",
    "faceDetection = cv2.CascadeClassifier('OneDrive/Belgeler/OpenCV/Kitap/DATA/haarcascades/haarcascade_frontalface_default.xml')\n",
    "faceLocation = faceDetection.detectMultiScale(prevFrame)\n",
    "    \n",
    "(faceX, faceY,w, h) = tuple(faceLocation[0])\n",
    "faceTracking = (faceX, faceY, w, h)\n",
    "\n",
    "roi = prevFrame[faceY : faceY + h, faceX : faceX + w]\n",
    "hsv_roi = cv2.cvtColor(roi,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "hist_roi = cv2.calcHist([hsv_roi],[0],None,[180],[0,180])\n",
    "cv2.normalize(hist_roi,hist_roi,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "parameters = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT , 10 ,1)\n",
    "\n",
    "while True:\n",
    "    ret,nextFrame = video.read()\n",
    "    hsv_NextFrame = cv2.cvtColor(nextFrame,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    target = cv2.calcBackProject([hsv_NextFrame],[0],hist_roi,[0,180],1)\n",
    "    ret,faceTracking = cv2.CamShift(target,faceTracking,parameters)\n",
    "\n",
    "    points = cv2.boxPoints(ret)\n",
    "    points = np.int0(points)\n",
    "\n",
    "    mark = cv2.polylines(nextFrame,[points],True,(0,255,255),5)\n",
    "\n",
    "    cv2.imshow('Takip',mark)\n",
    "\n",
    "    k = cv2.waitKey(10) & 0XFF\n",
    "\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1898bbfe-284b-4728-8ff6-1c38e8da3ee7",
   "metadata": {},
   "source": [
    "**meanShift()** & **CamShift()** algoritmaları ilk olarak yüz tespiti yapılmış sonra ise takibi yapılmıştır.Ancak bu uygulamalar geliştirilerek her türlü nesnenin takibi için kullanılması mümkün olabilmektedir.Öncelikle nesnenin konumuna ve boyutuna bir şekilde ulaşılması gerekliliğidir.Sonrasında meanshift ve camshift ile nesne takibi gerçekleştirilebilmektedir.\n",
    "\n",
    "Bu algoritmaların temel amacı renk yoğunluğu veya dağılımının tespit edilmesi olup nesne takip amaçlı değildir.Ancak ardışık frameler/çerçeveler arasında aynı yoğunluğu takip edebilmesinden ötürü nesne takip uygulamaları kullanılabilmektedir.\n",
    "\n",
    "Eğer sistem önce bir veri seti ile eğitilerek,eğitilmiş olduğu nesnenin tespiti ve takibi yaptılırsa off-line,eğer sistem anlık almış olduğu veri seti ile eğitilirse on-line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "842481da-0790-4af4-ac03-1a6582655133",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 1 for MIL,2 for GOTURN\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please choice your Tracker? 2\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "Unknown C++ exception from OpenCV code",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2832\\2122444144.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mroi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselectROI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtracker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mroi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: Unknown C++ exception from OpenCV code"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def trackerSelection():\n",
    "    print(\"Enter 1 for MIL,2 for GOTURN\")\n",
    "    choice = input(\"Please choice your Tracker?\")\n",
    "    \n",
    "    if choice == '1':\n",
    "        tracker = cv2.TrackerMIL()\n",
    "    elif choice == '2':\n",
    "        tracker = cv2.TrackerGOTURN()\n",
    "    return tracker\n",
    "\n",
    "tracker = trackerSelection()\n",
    "trackerName = str(tracker).split()[0][1:]\n",
    "camera = cv2.VideoCapture(\"OneDrive/Belgeler/OpenCV/Kitap/DATA/videoplayback_4.mp4\")\n",
    "ret,frame = camera.read()\n",
    "\n",
    "roi = cv2.selectROI(frame,False)\n",
    "ret = tracker.init(frame,roi)\n",
    "\n",
    "while True:\n",
    "    ret,frame = camera.read()\n",
    "    success,roi = tracker.update(frame)\n",
    "    \n",
    "    (x,y,w,h) = tuple(map(int,roi))\n",
    "    \n",
    "    if success:\n",
    "        p1 = (x,y)\n",
    "        p2 = (x + w , y + h)\n",
    "        cv2.rectangle(frame,p1,p2,(0,255,0),3)\n",
    "    else:\n",
    "        cv2.putText(frame,\"Failure!\",(100,200),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),3)\n",
    "        cv2.putText(frame,trackername,(20,400),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),3)\n",
    "        cv2.imshow(trackerName,frame)\n",
    "        \n",
    "        k = cv2.waitKey(10) & 0XFF\n",
    "        if k == 27:\n",
    "            break\n",
    "            \n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
